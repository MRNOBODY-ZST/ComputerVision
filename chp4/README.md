# MNIST手写数字识别实验报告

## 一、实验目的

通过这个实验主要是想学会用PyTorch搭建一个神经网络，然后在MNIST数据集上训练一个手写数字识别模型。虽然MNIST是个比较老的数据集了，但用来入门深度学习还是挺合适的。实验过程中可以熟悉PyTorch的基本用法，理解神经网络训练的流程，看看一个简单的多层感知机能达到什么效果。

## 二、实验环境

- 操作系统：Ubuntu Linux
- Python 3.10
- PyTorch 2.0
- 其他库：torchvision、matplotlib、numpy、scikit-learn

因为没有GPU，所以整个训练是在CPU上跑的，速度会慢一些但也还能接受。

## 三、实验方法与步骤

数据集用的是MNIST，包含60000张训练图片和10000张测试图片，每张图片是28×28的灰度图。在用之前先做了标准化处理，把像素值归一化到均值0.1307、标准差0.3081，这样训练会快一些也稳定一些。批次大小设成了128。

模型设计上用了一个三层的全连接网络，隐藏层的神经元数量分别是512、256、128。每层后面接ReLU激活函数和Dropout（丢弃率0.2）来防止过拟合。输入是把28×28的图片展平成784维向量，输出是10个类别的概率。整个模型大概有53万个参数。

训练配置方面，损失函数用的交叉熵，优化器是Adam，学习率0.001。一共训练了20个epoch，每个epoch跑完训练集后会在测试集上测一下准确率。

## 四、实验结果与分析

训练过程还算顺利。最开始几个epoch损失下降得很快，准确率也快速上升。到第5个epoch左右就开始变缓了，后面主要是在慢慢优化。最终训练集准确率99.20%，测试集98.44%，差距很小说明没怎么过拟合。

![\[训练曲线图\]](results/training_curves.png)

从预测样本来看，大部分都能正确识别，只有少数几个错的，而且那些错的确实写得比较潦草，人眼看着也费劲。

![\[预测样本图\]](results/prediction_samples.png)

看了一下混淆矩阵，数字1识别得最好，大概是因为形状简单。数字2、4、7稍微差一点，可能是因为手写变化比较大。有些数字之间会互相混淆，比如4和9，3和8，这都能理解，手写的时候确实容易像。

![\[混淆矩阵图\]](results/confusion_matrix.png)

整个训练用了大概3分钟，对于这种简单任务来说还行。最后测试集上97.5%的准确率，对一个基础的MLP来说已经不错了，虽然比不上CNN的99%+，但也在合理范围内。

## 五、实验总结

这次实验让我对神经网络的训练流程有了比较清楚的认识。之前学的那些前向传播、反向传播的概念，通过实际写代码变得具体了。看着损失一点点降下来，准确率慢慢涨上去，还是挺有成就感的。

几个体会：数据预处理确实重要，标准化之后训练快很多；Dropout的作用挺明显的，训练集和测试集准确率差距很小；Adam优化器用起来比较省心，不用太费心调学习率；批次大小128是个比较折中的选择。

当然也有一些不足的地方。首先模型比较简单，就是个全连接网络，把图片展平就丢失了空间信息。如果换成CNN应该会更好，因为CNN专门处理图像。另外没有用数据增强，如果加上旋转、平移这些操作应该能提高模型的鲁棒性。超参数也都是按经验设的，没有系统地调优过。

如果要改进的话，可以试试卷积神经网络、加数据增强、用学习率衰减策略，或者试试残差网络、批归一化这些技术。不过这个实验的重点不是追求最高准确率，而是理解基本原理和流程，从这个角度来说目标算是达到了。

通过这次实验算是对深度学习有了个初步的认识，知道了从数据到模型到训练到评估的完整流程。接下来打算学学CNN，在更复杂的数据集上试试。